{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960bdf0f-28b6-47f6-87f0-1c10be08d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f073fbc-28e3-44c0-87f3-857cdd77cda9",
   "metadata": {},
   "source": [
    "## Decision Tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5278ef-296e-4de7-89dd-0bb48007e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode():\n",
    "    def __init__(self):\n",
    "        self.feature = None\n",
    "        self.threshold = None\n",
    "        self.value = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f512572d-be97-48e9-a231-f782c9ac5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y)\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        res = []\n",
    "        for i in range(X.shape[0]):\n",
    "            row = X[i, ...]\n",
    "            node = self.root\n",
    "            while node.value == None:\n",
    "                if row[node.feature] < node.threshold:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "            res.append(node.value) \n",
    "        return np.asarray(res)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _entropy(y):\n",
    "        # best case (entropy = 0): all values belong to one class.\n",
    "        # worst case (binary, entropy = 1): 50% of values belong to one class, 50% - to another class\n",
    "        \n",
    "        probabilities = np.array(np.unique(y, return_counts=True)).T[:, 1]/len(y)\n",
    "        return np.sum(-probabilities * np.log2(probabilities + 1e-9)) # add 1e-9 to avoid log2(0)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _information_gain(y, y_left, y_right):\n",
    "        y_entropy = __class__._entropy(y)\n",
    "\n",
    "        y_left_entropy = __class__._entropy(y_left)\n",
    "        y_right_entropy = __class__._entropy(y_right)\n",
    "\n",
    "        y_left_weight = len(y_left) / len(y)\n",
    "        y_rigth_weight = len(y_right) / len(y)\n",
    "\n",
    "        weighted_entropy = y_left_weight * y_left_entropy + y_rigth_weight * y_right_entropy\n",
    "        return y_entropy - weighted_entropy\n",
    "\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        best_split = {'max_gain': -1}\n",
    "\n",
    "        if len(np.unique(y)) < 2:\n",
    "            return best_split\n",
    "            \n",
    "        num_features = X.shape[1]\n",
    "        for i in range(num_features):\n",
    "            feature_values = X[:, i]\n",
    "            \n",
    "            thresholds = np.unique(feature_values)\n",
    "            for threshold in thresholds:\n",
    "                mask = feature_values < threshold\n",
    "                X_left, X_right = X[mask, ...], X[~mask, ...]\n",
    "                y_left, y_right = y[mask], y[~mask]\n",
    "                \n",
    "                if not len(y_left) or not len(y_right):\n",
    "                    continue\n",
    "                    \n",
    "                information_gain = self._information_gain(y, y_left, y_right)\n",
    "                if information_gain > best_split['max_gain']:\n",
    "                    best_split['max_gain'] = information_gain\n",
    "                    best_split['feature'] = i\n",
    "                    best_split['threshold'] = threshold\n",
    "                    best_split['X_left'] = X_left\n",
    "                    best_split['y_left'] = y_left\n",
    "                    best_split['X_right'] = X_right\n",
    "                    best_split['y_right'] = y_right\n",
    "        return best_split\n",
    "\n",
    "    \n",
    "    def _build_tree(self, X, y):\n",
    "        best_split = self._best_split(X, y)\n",
    "        \n",
    "        node = TreeNode()\n",
    "        if best_split['max_gain'] != -1:\n",
    "            node.feature = best_split['feature']\n",
    "            node.threshold = best_split['threshold']\n",
    "            node.left = self._build_tree(best_split['X_left'], best_split['y_left'])\n",
    "            node.right = self._build_tree(best_split['X_right'], best_split['y_right'])\n",
    "        else:\n",
    "            node.value = np.bincount(y).argmax()\n",
    "            \n",
    "        return node\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5066ce-414e-49d2-ad02-f1328aaad0f4",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6885e818-53c5-455a-98c4-c35e6c0b4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = 1_000, \n",
    "                           n_features = 5,\n",
    "                           n_informative = 3,\n",
    "                           n_redundant = 0,\n",
    "                           n_classes = 3,\n",
    "                           n_clusters_per_class = 1,\n",
    "                           random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a136fdec-d303-45d4-93fc-f0e4a3cc10c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 5) (200, 5)\n"
     ]
    }
   ],
   "source": [
    "test_split = int(X.shape[0] * 0.2)\n",
    "\n",
    "X_train, X_test = X[:-test_split, ...], X[-test_split:, ...]\n",
    "y_train, y_test = y[:-test_split, ...], y[-test_split:, ...]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b21a09-0cff-4a07-a57a-7aa95c46e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTree()\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123cf542-c1bf-4679-96b3-9c2b6e22af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6129a91c-fc57-4a11-a132-f800753a69c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "sum(y_test == pred) / len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
